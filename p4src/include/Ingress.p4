#ifndef __INGRESS__
#define __INGRESS__

//new includes for the INT usage
#include "define.p4"
#include "int_source.p4"

#define CPU_CLONE_SESSION_ID 99
#define UN_BLOCK_MASK     0xffffffff000000000000000000000000

/*************************************************************************
****************  I N G R E S S   P R O C E S S I N G   ****************** (SOURCE/SINK NODE)
*************************************************************************/

control IngressPipeImpl (inout parsed_headers_t hdr,
                         inout local_metadata_t local_metadata,
                         inout standard_metadata_t standard_metadata) {

    action drop() {
        mark_to_drop(standard_metadata);
    }

    action set_output_port(port_num_t port_num) {
        standard_metadata.egress_spec = port_num;
    }
    action set_multicast_group(group_id_t gid) {
        log_msg("Multicast group set to:{}", {gid});
        standard_metadata.mcast_grp = gid;
        local_metadata.is_multicast = true;
    }

    direct_counter(CounterType.packets_and_bytes) unicast_counter; 
    table unicast {
        key = {
            hdr.ethernet.dst_addr: exact; 
        }
        actions = {
            set_output_port;
            drop;
            NoAction;
        }
        counters = unicast_counter;
        default_action = NoAction();
    }

    direct_counter(CounterType.packets_and_bytes) multicast_counter;
    table multicast {
        key = {
            hdr.ethernet.dst_addr: ternary;
        }
        actions = {
            set_multicast_group;
            drop;
        }
        counters = multicast_counter;
        const default_action = drop;
    }

    direct_counter(CounterType.packets_and_bytes) l2_firewall_counter;
    table l2_firewall {
	    key = {
	        hdr.ethernet.dst_addr: exact;
	    }
	    actions = {
	        NoAction;
	    }
    	counters = l2_firewall_counter;
    }

    action set_next_hop(mac_addr_t next_hop) {
	    hdr.ethernet.src_addr = hdr.ethernet.dst_addr;
	    hdr.ethernet.dst_addr = next_hop;
	    hdr.ipv6.hop_limit = hdr.ipv6.hop_limit - 1;
    }

    //K-Shortest Path Routing Table
    direct_counter(CounterType.packets_and_bytes) routing_v6_kShort_counter;
    table routing_v6_kShort {            
	    key = {
	        hdr.ipv6.dst_addr: lpm;
        }
        actions = {
	        set_next_hop;
        }
        counters = routing_v6_kShort_counter;
    }

    //ECMP Path Routing Table, ternary match so i can abstract the hosts to their switchs (we use a maks to match the first 64 bits of the address)
    //action_selector(HashAlgorithm.crc16, 32w64, 32w10) ip6_ECMP_selector;
    direct_counter(CounterType.packets_and_bytes) routing_v6_ECMP_counter;
    table routing_v6_ECMP {
        key = {
            hdr.ipv6.src_addr   : ternary;
            hdr.ipv6.dst_addr   : ternary;
            hdr.ipv6.flow_label : exact;
        }
        actions = {
            set_next_hop;
        }
        counters = routing_v6_ECMP_counter;
        //implementation = ip6_ECMP_selector;
    }

    // TODO calc checksum
    action set_next_hop_v4(mac_addr_t next_hop) {
        hdr.ethernet.src_addr = hdr.ethernet.dst_addr;
        hdr.ethernet.dst_addr = next_hop;
        hdr.ipv4.ttl = hdr.ipv4.ttl - 1;
        local_metadata.ipv4_update = true;
    }

    direct_counter(CounterType.packets_and_bytes) routing_v4_counter;
    table routing_v4 {
        key = {
            hdr.ipv4.dst_addr: lpm;
        }
        actions = {
            set_next_hop_v4;
        }
        counters = routing_v4_counter;
    }

    /*
     * NDP neighbor solicitation reply table and actions. The CPU informed about all the nodes, so the first switch replies itself to them immediately.
     * Handles NDP neighbor solicitation message and send neighbor advertisement to the sender.
     */
    action ndp_ns_to_na(mac_addr_t target_mac) {
        hdr.ethernet.src_addr = target_mac;
        hdr.ethernet.dst_addr = IPV6_MCAST_01;
        ipv6_addr_t host_ipv6_tmp = hdr.ipv6.src_addr;
        hdr.ipv6.src_addr = hdr.ndp_n.target_addr;
        hdr.ipv6.dst_addr = host_ipv6_tmp;
        hdr.icmpv6.type = ICMP6_TYPE_NA;
        hdr.ndp_n.flags = NDP_FLAG_ROUTER | NDP_FLAG_OVERRIDE;
        hdr.ndp_option.setValid();
        hdr.ndp_option.type = NDP_OPT_TARGET_LL_ADDR;
        hdr.ndp_option.length = 1;
        hdr.ndp_option.value = target_mac;
        hdr.ipv6.next_header = PROTO_ICMPV6;
        standard_metadata.egress_spec = standard_metadata.ingress_port;
        // we use the same header so no need to set old one as invalid and new one as valid
    }

    direct_counter(CounterType.packets_and_bytes) ndp_n_reply_table_counter;
    table ndp_n_reply_table {
        key = {
            hdr.ndp_n.target_addr: exact;
        }
        actions = {
            ndp_ns_to_na;
        }
        counters = ndp_n_reply_table_counter;
    }

    /*
     * NDP router solicitation reply table and actions.
     * Handles NDP router solicitation message and send router advertisement to the sender.
     */
    action ndp_rs_to_ra(mac_addr_t my_router_mac, ipv6_addr_t my_router_ipv6) { 

        // Ethernet
        hdr.ethernet.dst_addr = hdr.ethernet.src_addr;
        hdr.ethernet.src_addr = my_router_mac;

        // IPv6
        hdr.ipv6.dst_addr = hdr.ipv6.src_addr;
        hdr.ipv6.src_addr = my_router_ipv6;
        hdr.ipv6.payload_len = 16w24;         // value in bytes, ICMPv6 + NDP RA + NDP Option length (32 + 96 + 64 = 192 bits = 24 bytes)
        hdr.ipv6.next_header = PROTO_ICMPV6;


        // ICMPv6
        hdr.icmpv6.type = ICMP6_TYPE_RA;       // Router Advertisement

        // RA fields
        hdr.ndp_ra.setValid();
        hdr.ndp_ra.cur_hop_limit = 64;         // Example default
        hdr.ndp_ra.auto_config_flags = 0;      // m,o, and reserved flags
        hdr.ndp_ra.router_lifetime = 1800;     // 30 minutes
        hdr.ndp_ra.reachable_time = 0;         // Set as needed (no suggestion)
        hdr.ndp_ra.retrans_timer = 0;          // Set as needed (use your own value)

        // Optional: Include link-layer address option
        hdr.ndp_option.setValid();
        hdr.ndp_option.type = NDP_OPT_TARGET_LL_ADDR;
        hdr.ndp_option.length = 1;             // Length of NDP Options Header in 8-byte (64 bits) units
        hdr.ndp_option.value = my_router_mac;

        // Send back out the same port
        standard_metadata.egress_spec = standard_metadata.ingress_port;

        // set old header as invalid
        hdr.ndp_rs.setInvalid();
    }

    direct_counter(CounterType.packets_and_bytes) ndp_r_reply_table_counter;
    table ndp_r_reply_table {
        key = {                                 //needs at least a key
            1w0 : exact;                        //dummy key to trigger the action
        }
        actions = {
            ndp_rs_to_ra;                       //We want to always trigger this action
        }
        counters = ndp_r_reply_table_counter;
    }

    action srv6_end() {}

    action srv6_usid_un() {
        log_msg("srv6_usid_un action");
        hdr.ipv6.dst_addr = (hdr.ipv6.dst_addr & UN_BLOCK_MASK) | ((hdr.ipv6.dst_addr << 16) & ~((bit<128>)UN_BLOCK_MASK));
    }

    action srv6_usid_ua(ipv6_addr_t next_hop) {
        log_msg("srv6_usid_ua action");
        hdr.ipv6.dst_addr = (hdr.ipv6.dst_addr & UN_BLOCK_MASK) | ((hdr.ipv6.dst_addr << 32) & ~((bit<128>)UN_BLOCK_MASK));
        local_metadata.xconnect = true;

        local_metadata.ua_next_hop = next_hop;
    }

    action srv6_end_x(ipv6_addr_t next_hop) {
        hdr.ipv6.dst_addr = (hdr.ipv6.dst_addr & UN_BLOCK_MASK) | ((hdr.ipv6.dst_addr << 32) & ~((bit<128>)UN_BLOCK_MASK));
        local_metadata.xconnect = true;

        local_metadata.ua_next_hop = next_hop;
    }

    action srv6_end_dx6() {   //no more SRv6 steps, OG packet was IPv6
        hdr.ipv6.version = hdr.ipv6_inner.version;
        hdr.ipv6.dscp = hdr.ipv6_inner.dscp;
        hdr.ipv6.ecn = hdr.ipv6_inner.ecn;
        hdr.ipv6.flow_label = hdr.ipv6_inner.flow_label;
        hdr.ipv6.payload_len = hdr.ipv6_inner.payload_len;    //restore packet size (containing INT if used, INT SORCE AND TRANSIT must keep it updated)
        hdr.ipv6.next_header = hdr.ipv6_inner.next_header;
        hdr.ipv6.hop_limit = hdr.ipv6_inner.hop_limit;
        hdr.ipv6.src_addr = hdr.ipv6_inner.src_addr;
        hdr.ipv6.dst_addr = hdr.ipv6_inner.dst_addr;

        hdr.ipv6_inner.setInvalid();
        hdr.srv6h.setInvalid();
        hdr.srv6_list[0].setInvalid();
    }

    action srv6_end_dx4()  {   //no more SRv6 steps, OG packet was IPv4
        hdr.srv6_list[0].setInvalid();
        hdr.srv6h.setInvalid();
        hdr.ipv6.setInvalid();
        hdr.ipv6_inner.setInvalid();

        hdr.ethernet.ether_type = ETHERTYPE_IPV4;
    } 

    direct_counter(CounterType.packets_and_bytes) srv6_localsid_table_counter;
    table srv6_localsid_table {
        key = {
            hdr.ipv6.dst_addr: lpm;
        }
        actions = {
            srv6_end;
            srv6_end_x;             //unknown, not being used
            srv6_end_dx6;           //sink
            srv6_end_dx4;           //sink
            srv6_usid_un;           //transit
            srv6_usid_ua;           //transit
            NoAction;
        }
        default_action = NoAction;
        counters = srv6_localsid_table_counter;
    }

    action xconnect_act(mac_addr_t next_hop) {
        hdr.ethernet.src_addr = hdr.ethernet.dst_addr;
        hdr.ethernet.dst_addr = next_hop;
    }

    direct_counter(CounterType.packets_and_bytes) xconnect_table_counter;
    table xconnect_table {
        key = {
            local_metadata.ua_next_hop: lpm;
        }
        actions = {
            xconnect_act;
            NoAction;
        }
        default_action = NoAction;
        counters = xconnect_table_counter;
    }

    action usid_encap_1(ipv6_addr_t src_addr, ipv6_addr_t s1) { //only one segment, so the SRH is not used (we change the IPv6 header), only the ipv6_inner to save the OG info
        log_msg("usid_encap_1 action");
        hdr.ipv6_inner.setValid();

        hdr.ipv6_inner.version = 6;
        hdr.ipv6_inner.ecn = hdr.ipv6.ecn;
        hdr.ipv6_inner.dscp = hdr.ipv6.dscp;
        hdr.ipv6_inner.flow_label = hdr.ipv6.flow_label;
        hdr.ipv6_inner.payload_len = hdr.ipv6.payload_len;
        hdr.ipv6_inner.next_header = hdr.ipv6.next_header;
        hdr.ipv6_inner.hop_limit = hdr.ipv6.hop_limit;
        hdr.ipv6_inner.src_addr = hdr.ipv6.src_addr;
        hdr.ipv6_inner.dst_addr = hdr.ipv6.dst_addr;

        hdr.ipv6.payload_len = hdr.ipv6.payload_len + 40;
        hdr.ipv6.next_header = PROTO_IPV6;
        hdr.ipv6.src_addr = src_addr;                            //uN of the current device
        hdr.ipv6.dst_addr = s1;
    }

    action usid_encap_2(ipv6_addr_t src_addr, ipv6_addr_t s1, ipv6_addr_t s2) { //two segments, so the SRH is used to store future ones
        log_msg("usid_encap_2 action");
        hdr.ipv6_inner.setValid();

        hdr.ipv6_inner.version = 6;
        hdr.ipv6_inner.ecn = hdr.ipv6.ecn;
        hdr.ipv6_inner.dscp = hdr.ipv6.dscp;
        hdr.ipv6_inner.flow_label = hdr.ipv6.flow_label;
        hdr.ipv6_inner.payload_len = hdr.ipv6.payload_len;
        hdr.ipv6_inner.next_header = hdr.ipv6.next_header;
        hdr.ipv6_inner.hop_limit = hdr.ipv6.hop_limit;
        hdr.ipv6_inner.src_addr = hdr.ipv6.src_addr;
        hdr.ipv6_inner.dst_addr = hdr.ipv6.dst_addr;

        hdr.ipv6.payload_len = hdr.ipv6.payload_len + 40 + 24;
        hdr.ipv6.next_header = PROTO_SRV6;
        hdr.ipv6.src_addr = src_addr;                            //uN of the current device
        hdr.ipv6.dst_addr = s1;

        hdr.srv6h.setValid();
        hdr.srv6h.next_header = PROTO_IPV6;         //change to what ipv6 used to point as next
        hdr.srv6h.hdr_ext_len = 0x2;
        hdr.srv6h.routing_type = 0x4;
        hdr.srv6h.segment_left = 0;
        hdr.srv6h.last_entry = 0;
        hdr.srv6h.flags = 0;
        hdr.srv6h.tag = 0;

        hdr.srv6_list[0].setValid();
        hdr.srv6_list[0].segment_id = s2;
    }

    direct_counter(CounterType.packets_and_bytes) srv6_encap_table_counter;
    table srv6_encap {      //when the OG packet is IPv6
        key = {
           hdr.ipv6.src_addr: ternary; 
           hdr.ipv6.dst_addr: ternary;  
           hdr.ipv6.flow_label: ternary;     
        }
        actions = {
            usid_encap_1;
            usid_encap_2;
            NoAction;
        }
        default_action = NoAction;
        counters = srv6_encap_table_counter;
    }

    action usid_encap_1_v4(ipv6_addr_t src_addr, ipv6_addr_t s1) {
        hdr.ipv6.setValid();

        hdr.ipv6.version = 6;
        hdr.ipv6.dscp = hdr.ipv4.dscp; 
        hdr.ipv6.ecn = hdr.ipv4.ecn; 
        hash(hdr.ipv6.flow_label, 
                HashAlgorithm.crc32, 
                (bit<20>) 0, 
                { 
                    hdr.ipv4.src_addr,
                    hdr.ipv4.dst_addr,
                    local_metadata.ip_proto,
                    local_metadata.l4_src_port,
                    local_metadata.l4_dst_port
                },
                (bit<20>) 1048575);
        hdr.ipv6.payload_len = hdr.ipv4.total_len;
        hdr.ipv6.next_header = PROTO_IP_IN_IP;
        hdr.ipv6.hop_limit = hdr.ipv4.ttl;
        hdr.ipv6.src_addr = src_addr;
        hdr.ipv6.dst_addr = s1;

        hdr.ethernet.ether_type = ETHERTYPE_IPV6;
    }

    action usid_encap_2_v4(ipv6_addr_t src_addr, ipv6_addr_t s1, ipv6_addr_t s2) {
        hdr.ipv6.setValid();

        hdr.ipv6.version = 6;
        hdr.ipv6.ecn = hdr.ipv4.ecn;
        hdr.ipv6.dscp = hdr.ipv4.dscp;
        hash(hdr.ipv6.flow_label, 
                HashAlgorithm.crc32, 
                (bit<20>) 0, 
                { 
                    hdr.ipv4.src_addr,
                    hdr.ipv4.dst_addr,
                    local_metadata.ip_proto,
                    local_metadata.l4_src_port,
                    local_metadata.l4_dst_port
                },
                (bit<20>) 1048575);        
        hdr.ipv6.payload_len = hdr.ipv4.total_len + 24;
        hdr.ipv6.next_header = PROTO_SRV6;
        hdr.ipv6.hop_limit = hdr.ipv4.ttl;
        hdr.ipv6.src_addr = src_addr;
        hdr.ipv6.dst_addr = s1;

        hdr.srv6h.setValid();
        hdr.srv6h.next_header = PROTO_IP_IN_IP;   //since is encapsulating ipv4 the next one is always IPv4
        hdr.srv6h.hdr_ext_len = 0x2;
        hdr.srv6h.routing_type = 0x4;
        hdr.srv6h.segment_left = 0;
        hdr.srv6h.last_entry = 0;
        hdr.srv6h.flags = 0;
        hdr.srv6h.tag = 0;

        hdr.srv6_list[0].setValid();
        hdr.srv6_list[0].segment_id = s2;

        hdr.ethernet.ether_type = ETHERTYPE_IPV6;
    }

    // create one group 
    action_selector(HashAlgorithm.crc16, 32w64, 32w10) ecmp_selector;
    direct_counter(CounterType.packets_and_bytes) srv6_encap_v4_table_counter;
    table srv6_encap_v4 {          //when the OG packet is IPv4
        key = {
            hdr.ipv4.dscp: exact;
            hdr.ipv4.dst_addr: lpm;

            hdr.ipv4.src_addr: selector;
            hdr.ipv4.dst_addr: selector;
            local_metadata.ip_proto: selector;
            local_metadata.l4_src_port: selector;
            local_metadata.l4_dst_port: selector;
        }
        actions = {
            usid_encap_1_v4;
            usid_encap_2_v4;
            NoAction;
        }
        default_action = NoAction;
        implementation = ecmp_selector;
        counters = srv6_encap_v4_table_counter;
    }

    /*
     * ACL table  and actions.
     * Clone the packet to the CPU (PacketIn) or drop.
     */
    action clone_to_cpu() {
        local_metadata.perserv_CPU_meta.ingress_port = standard_metadata.ingress_port;
        local_metadata.perserv_CPU_meta.egress_port = CPU_PORT;                         //the packet only gets the egress right before egress, so we use CPU_PORT value
        local_metadata.perserv_CPU_meta.to_CPU = true;
        clone_preserving_field_list(CloneType.I2E, CPU_CLONE_SESSION_ID, CLONE_FL_clone3);
    }

    direct_counter(CounterType.packets_and_bytes) acl_counter;
    table acl {
        key = {
            standard_metadata.ingress_port: ternary;
            hdr.ethernet.dst_addr: ternary;
            hdr.ethernet.src_addr: ternary;
            hdr.ethernet.ether_type: ternary;
            local_metadata.ip_proto: ternary;
            local_metadata.icmp_type: ternary;
            local_metadata.l4_src_port: ternary;
            local_metadata.l4_dst_port: ternary;
        }
        actions = {
            clone_to_cpu;
            drop;
        }
        counters = acl_counter;
    }

    // QoS-Aware Scheduling: DSCP-to-Queue Mapping - Feature for P4-NEON
    action set_queue_ef() {
        local_metadata.queue_id = 7;
    }

    action set_queue_af() {
        local_metadata.queue_id = 5;
    }

    action set_queue_cs() {
        local_metadata.queue_id = 3;
    }

    action set_queue_be() {
        local_metadata.queue_id = 0;
    }

    table dscp_qos_mapping {
        key = {
            local_metadata.OG_dscp: exact;
        }
        actions = {
            set_queue_ef;
            set_queue_af;
            set_queue_cs;
            set_queue_be;
            NoAction;
        }
        default_action = set_queue_be;
    }

    // QoS-Aware Scheduling: Queue Occupancy Register for congestion detection
    // Tracks queue depth per queue ID for INT Analyzer to detect congestion
    register<bit<16>>(8) queue_occupancy_register;  // 8 instances for 8 queues

    // RFC 2544 Performance Evaluation Registers
    // Store test metadata for analysis
    register<bit<32>>(256) rfc2544_test_flow_id;   //flow identifier for tracking
    register<bit<32>>(256) rfc2544_test_type;      //test identifier (1=throughput, 2=latency, 3=loss, 4=jitter)

    action update_queue_occupancy() {
        // Log current queue depth for INT export
        // This value will be read by INT Analyzer for adaptive routing
        log_msg("Queue occupancy register updated for queue_id:{}", {local_metadata.queue_id});
    }

    table queue_occupancy_update {
        key = {
            local_metadata.queue_id: exact;
        }
        actions = {
            update_queue_occupancy;
            NoAction;
        }
        default_action = NoAction;
    }

    // QoS Priority Override: Prevent non-EF traffic from using EF queue
    action enforce_qos_boundary() {
        // If packet tries to use higher queue than its DSCP allows, downgrade it
        // This prevents queue spoofing or cross-class interference
        log_msg("QoS boundary enforcement: queue_id clamped for DSCP:{}", {local_metadata.OG_dscp});
    }

    table qos_boundary_enforcement {
        key = {
            local_metadata.OG_dscp: exact;
            local_metadata.queue_id: exact;
        }
        actions = {
            enforce_qos_boundary;
            NoAction;
        }
        default_action = NoAction;
    }

    // RFC 2544 Test Configuration Table
    // Sets test parameters for performance evaluation
    action set_rfc2544_test_config(bit<32> test_id, bit<8> qos_class) {
        local_metadata.rfc2544_test_id = test_id;
        local_metadata.qos_class = qos_class;
        log_msg("RFC2544: Test ID {} configured", {test_id});
    }

    action record_timestamp() {
        // Store ingress timestamp for latency measurement
        local_metadata.ingress_timestamp = standard_metadata.ingress_global_timestamp;
    }

    table rfc2544_test_config {
        key = {
            hdr.ipv6.dst_addr: ternary;
            local_metadata.l4_dst_port: exact;
        }
        actions = {
            set_rfc2544_test_config;
            record_timestamp;
            NoAction;
        }
        default_action = NoAction;
    }

    apply {
        //-----------------Set packet priority, local_metadata.OG_dscp is 0 by default which means priority 0 (best effort)
        if(hdr.intl4_shim.isValid())     {local_metadata.OG_dscp = hdr.intl4_shim.udp_ip_dscp;} //when INT is used, the OG DSCP value is in the shim header
        else if(hdr.ipv6_inner.isValid()){local_metadata.OG_dscp = hdr.ipv6_inner.dscp;}        //for SRv6 used, except encapsulation of IPv4 with just one segemnt
        else if(hdr.ipv6.isValid())      {local_metadata.OG_dscp = hdr.ipv6.dscp;}              //no SRv6 or encapsulation of IPv4 with just one segemnt
        else if(hdr.ipv4.isValid())      {local_metadata.OG_dscp = hdr.ipv4.dscp;}              //no encapsulation of IPv4 
        
        //the value is 0 by default (best effort)
        //set_priority_from_dscp.apply();                       //set the packet priority based on the DSCP value
        standard_metadata.priority = local_metadata.OG_dscp[5:3];
        if(standard_metadata.priority != 0){log_msg("Packet priority changed to:{}", {standard_metadata.priority});}

        //the other 3 bits are the drop precedence, we don't use it
        
        //QoS-Aware Scheduling: Apply DSCP-to-Queue mapping for priority scheduling
        dscp_qos_mapping.apply();
        if(local_metadata.queue_id != 0){
            log_msg("QoS Queue assigned:{}", {local_metadata.queue_id});
        }
        
        //QoS-Aware Scheduling: Update queue occupancy for congestion visibility
        queue_occupancy_update.apply();
        
        //QoS-Aware Scheduling: Enforce QoS class boundaries (prevent spoofing)
        qos_boundary_enforcement.apply();
        
        //RFC 2544: Apply test configuration
        if(local_metadata.OG_dscp == 46 || local_metadata.OG_dscp == 34) {
            rfc2544_test_config.apply();
        }
        
        //---------------------------------------------------------------------------ACL Support
        if(hdr.ethernet.ether_type == ETHERTYPE_LLDP && hdr.ethernet.dst_addr == 1652522221582){  //LLDP multicast packet with dst ethernet (01:80:c2:00:00:0e), meant only for this switch, so do not forward it
            log_msg("It's an LLDP multicast packet destined to this switch, not meant to be forwarded");
            return;
        }
        if (hdr.packet_out.isValid()) {     //Came from the CPU, meant to be forwarded to the port defined in it
            log_msg("Packet from CPU, forwarding it to port:{}", {hdr.packet_out.egress_port});
            standard_metadata.egress_spec = hdr.packet_out.egress_port;
            hdr.packet_out.setInvalid();
            exit;                           //finish the Ingress here, it can probably also be return, and have the same effect, but this is more explicit;
        }
        else if(acl.apply().hit){          //Not from CPU and its acl pkt
            log_msg("ACL hit, cloned to CPU, end of processing");
            mark_to_drop(standard_metadata);
            return;
        }
        //---------------------------------------------------------------------------

        //---------------------------------------------------------------------------Drop packets with hop limit 0
        if(hdr.ipv6.isValid() && hdr.ipv6.hop_limit == 0) {
            drop();
        }

        //---------------------------------------------------------------------------Forwarding ICMPv6 NDP packets
        if(hdr.icmpv6.isValid()) {
            if (hdr.icmpv6.type == ICMP6_TYPE_NS){
                log_msg("ICMPv6, NDP NS packet detected, sending NDP NA to the sender");
                ndp_n_reply_table.apply();
                return;
            }
            else if (hdr.icmpv6.type == ICMP6_TYPE_RS) {
                log_msg("ICMPv6, NDP RS packet detected, sending NDP RA to the sender");
                ndp_r_reply_table.apply();
                return;
            }
            else if (hdr.icmpv6.type == ICMP6_TYPE_RA){             //usualy they are from another router, destined to this router, but currently we don't need their info
                log_msg("Detected incoming ICMPv6 NDP RA packet, no support for it, dropping it");
                mark_to_drop(standard_metadata);
                return;
            }
            else{
                log_msg("ICMPv6 packet detected, type:{} not needed, dropping", {hdr.icmpv6.type});
                mark_to_drop(standard_metadata);
                return;
            }
        }

        //commented because regular IPv6 packets were being dropped by the firewall, requires further testing and tinkering
        //---------------------------------------------------------------------------Firewall check (we allow IPv6 broadcast to locat the other hosts in the network)
	    /*if (!l2_firewall.apply().hit && hdr.ethernet.dst_addr != 281474976710655) {                      //checks if hdr.ethernet.dst_addr is listed in the table (only contains myStationMac)
            log_msg("L2 firewall hit failed for this packet, dropping it");
            /*log_msg("hdr.ethernet.src_addr:{}", {hdr.ethernet.src_addr});
            log_msg("hdr.ethernet.dst_addr:{}", {hdr.ethernet.dst_addr});
            log_msg("hdr.ethernet.ether_type:{}", {hdr.ethernet.ether_type});
            log_msg("hdr.ipv6.next_header:{}", {hdr.ipv6.next_header});
            log_msg("hdr.ipv6.src_addr:{}", {hdr.ipv6.src_addr});
            log_msg("hdr.ipv6.dst_addr:{}", {hdr.ipv6.dst_addr});
            mark_to_drop(standard_metadata);
            return;
        }*/
        
        //----------------SRv6 Behavior (SRv6 LocalSID Table) (decapsulate, forward to next segment, manipulate packet, etc.)
        switch(srv6_localsid_table.apply().action_run) { //uses hdr.ipv6.dst_addr to decided the action, use next segment or end SRv6
            srv6_end: {
                // support for reduced SRH
                if (hdr.srv6h.segment_left > 0) {
                    // set destination IP address to next segment
                    hdr.ipv6.dst_addr = local_metadata.next_srv6_sid;
                    // decrement segments left
                    hdr.srv6h.segment_left = hdr.srv6h.segment_left - 1;
                } else {
                    // set destination IP address to next segment
                    hdr.ipv6.dst_addr = hdr.srv6_list[0].segment_id;
                }
            }
            srv6_end_dx4: {
                routing_v4.apply();
            }
        }
        //----------------Detect recirculation
        if(standard_metadata.instance_type == PKT_INSTANCE_TYPE_INGRESS_RECIRC) {
            local_metadata.int_meta.sink = true;        //restore status as being sink, no longer need but it's correct (only sinks lead to recirculations, after cloning)
            local_metadata.recirculated_srv6_flag = true;
            standard_metadata.egress_spec = local_metadata.perserv_meta.egress_spec;   //restore egress_spec to the INT collector port
            log_msg("recirculated packet, restored sink status and Removed SR headers, terminating ingress processing sonner");
            return;                                     //recirculated just to remove headers used by SRv6, beacuse we are it's sink, so we stop here
        }

        // SRv6 Encapsulation
        if (hdr.ipv4.isValid() && !hdr.ipv6.isValid()) {
            srv6_encap_v4.apply();
        } else {
            srv6_encap.apply(); //uses hdr.ipv6 and compares to this nodes rules to decide if it encapsulates into SRv6 or not
        }

        //-----------------L3: Forwarding by IP -> MAC address
        if (!local_metadata.xconnect) {       //No SRv6 ua_next_hop 
            //first we try doing ECMP routing, if it fails we do k-Shortest Path
            //uses hdr.ipv6.dst_addr (and others) to set hdr.ethernet.dst_addr
            if(!routing_v6_ECMP.apply().hit){
                if(!routing_v6_kShort.apply().hit){
                    log_msg("No route found for IPv6 packet!");
                }
            }
        } else {                              //SRv6 ua_next_hop
            xconnect_table.apply();           //uses local_metadata.ua_next_hop to set hdr.ethernet.dst_addr
        }
        

        //-----------------L2: Forwarding by MAC address -> Port
        if(!unicast.apply().hit){            //uses hdr.ethernet.dst_addr to set egress_spec
            log_msg("unicast failed, trying multicast");
            if(!multicast.apply().hit){  
                log_msg("multicast failed");
            }
        }

        //-----------------INT processing portion        
        if(hdr.udp.isValid() || hdr.tcp.isValid()) {        //just track higer level connections. set if current hop is source or sink to the packet
            process_int_source_sink.apply(hdr, local_metadata, standard_metadata);
        }
        
        if (local_metadata.int_meta.source == true) {       //(source) INSERT INT INSTRUCTIONS HEADER
            log_msg("I am INT source for this packet origin, checking flow");
            hdr.intl4_shim.setInvalid(); 
            process_int_source.apply(hdr, local_metadata);
        }
        if (local_metadata.int_meta.sink == true && hdr.int_header.isValid()) { //(sink) and the INT header is valid
            // clone packet for Telemetry Report Collector
            log_msg("I am sink of this packet and i will clone it");
            //------------Prepare info for report
            local_metadata.perserv_meta.ingress_port = standard_metadata.ingress_port;      
            local_metadata.perserv_meta.deq_qdepth = standard_metadata.deq_qdepth;
            local_metadata.perserv_meta.ingress_global_timestamp = standard_metadata.ingress_global_timestamp;

            clone_preserving_field_list(CloneType.I2E, REPORT_MIRROR_SESSION_ID, CLONE_FL_1);
        }
    }
}

#endif